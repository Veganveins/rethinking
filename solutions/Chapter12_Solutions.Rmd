---
title: "Chapter12 Solutions"
output: pdf_document
---

https://rpubs.com/jiayuans/Assignment_10#:~:text=What%20kind%20of%20link%20function,for%20an%20ordinal%20response%20variable.

# Easy

1. What is the difference between an ordered categorical variable and an unordered one? Define
and then give an example of each.

_Ordered categorical: something like education, where "middle school" is inherently "less" than something like a Master's degree_

_Unordered categorical: something like fruit, where something like "apple" does not necessesarily imply whether it is greater or less than something like "banana"_

2. What kind of link function does an ordered logistic regression employ? How does it differ
from an ordinary logit link?

_The conventional solution is to use a cumulative link function. The cumulative link handles the cumulative probabilities of the response variable rather than the discrete probability of a single even_

3. When count data are zero-inflated, using a model that ignores zero-inflation will tend to induce which kind of inferential error?

_It will likely lead to underestimation of the rate of events, because a count distribution with extra zeros added to it will have a lower mean_

4. Over-dispersion is common in count data. Give an example of a natural process that might
produce over-dispersed counts. Can you also give an example of a process that might produce underdispersed counts?

_Over-dispersion refers to "fat tails" where extreme events are common. In more academic terms, "when the observed variance is higher than the variance of a theoretical model." One example of a natural process that might produce over-dispersed counts is the amount of damage caused by hurricanes. In most cases, hurricanes cause some damage but extreme events are rare. However, when storms are particularly severe, the amount of damage can be extraordinarily high. Under-dispersion refers to data where the response has very little variation, regardless of variation in predictor variables. A process that might produce under-dispersed counts could be something like the number of calories needed to survive. The average would be close to 2,000 and even the most active athletes would rarely need more than 10,000 calories per day._

# Medium

1. At a certain university, employees are annually rated from 1 to 4 on their productivity, with 1 being least productive and 4 most productive. In a certain department at this certain university in a certain year, the numbers of employees receiving each rating were (from 1 to 4): 12, 36, 7, 41. Compute the log cumulative odds of each rating.

```{r}
library(data.table)
productivity = c(1,2,3,4)
ratings = c(12, 36, 7, 41)
dat = data.table(productivity = productivity, n_employees = ratings)

ggplot(dat, aes(productivity, n_employees))+
  geom_bar(stat = 'identity', position = 'dodge')+
  ggtitle('Histogram of Discrete Response in the Sample')
```

```{r}
dat[, rating_prob := n_employees / sum(dat$n_employees)]
dat[, cumulative_prob := cumsum(rating_prob)]
dat
```

Here we have the data represented in terms of discrete probability (rating_prob) as well as the cumulative probability of each rating.

```{r}
dat[, log_cumulative_odds := log(cumulative_prob/(1-cumulative_prob))]
dat
```

Notice that the cumulative log odds of the largest value (4) is infinity. This is because log(1/(1-1)) is infinity. Since we know the largest response value always has a cumulative probability of 1, we effectively get it "for free."

2. Make a version of figure 12.5 for this ratings data.

```{r}
# plot the discrete probability in blue along with cumulative probability in grey

# plot the cumulative prob points*
plot( dat$productivity , dat$cumulative_prob , xlab="rating" , ylab="cumulative proportion" ,
xlim=c(0.7,4.3) , ylim=c(0,1) , xaxt="n", type = 'b' )
axis( 1 , at=1:4 , labels=1:4 )

# plot gray cumulative probability lines*
for ( x in 1:4 ) lines( c(x,x) , c(0,dat$cumulative_prob[x]) , col="gray" , lwd=2 )
# plot blue discrete probability segments
for ( x in 1:4 ) lines( c(x,x)+0.1 , c(dat$cumulative_prob[x]-dat$rating_prob[x],dat$cumulative_prob[x]) , col="slateblue" , lwd=2 )
# add number labels
text( 1:4+0.2 , dat$cumulative_prob , labels=1:4 , col="slateblue" )
```

# Can you modify the derivation of the zero-inflated Poisson distribution (ZIPoisson) from the chapter to construct a zero-inflated binomial distribution?

Here is the dzipois model from the chapter:
```{r}
#m12.3 <- ulam(
#alist(
#y ~ dzipois( p , lambda ),
#logit(p) <- ap,
#log(lambda) <- al,
#ap ~ dnorm( -1.5 , 1 ),
#al ~ dnorm( 1 , 0.5 )
#) , data=list(y=y) , chains=4 )

```

y ~ Binomial(n,p)

The probability of a zero, mixing together both processes, is: 

_Pr(0|p0, q, n) = p0 + (1 − p0)(1 − q)^n_

The probability of any particular non-zero observation y is the same as the probability of observing y events of type A and (n-y) events of type B is: (formula modified from page 315)

_Pr(y|p0, q, n) = (1 − p0)(n!/(y!(n − y)!)(q^y)((1 − q)^(n−y))_

_I'm honestly not fully sure where all this math comes from..._

# Hard

1. In 2014, a paper was published that was entitled "Female hurricanes are deadlier than male
hurricanes."

```{r}
library(rethinking)
data(Hurricanes)
d <- Hurricanes
head(d)
```

### a. Predict deaths using Poisson model of deaths on feminity
```{r}
dat_list = list(deaths = d$deaths,
                fem = d$femininity)

fem_mod <- ulam(
alist(
deaths ~ dpois( lambda ),
log(lambda) <- a + b*fem,
a ~ dnorm(0,3),
b ~ dnorm(0,3)
), data=dat_list , iter = 3000, chains=4 , log_lik=TRUE )
```

### b. Predict deaths using an intercept-only Poisson model
```{r}
int_mod <- ulam(
alist(
deaths ~ dpois( lambda ),
log(lambda) <- a,
a ~ dnorm(0,3)
), data=dat_list , iter = 3000, chains=4 , log_lik=TRUE )

```
### c. Compare the two
```{r}
compare(int_mod, fem_mod)
```
The model that includes femininity of name is better.

### d. How strong is the association between feminity of name and deaths? 
```{r}
precis(fem_mod)
```
THe association between femininity of name and deaths appears to be weakly positive (between .06 and .09).

### e. Which storms does the model fit (retrodict) well? Which storms does it fit poorly?

```{r}
# matrix of predictions for each row of data
y.preds = link(fem_mod, data = list(deaths = d$deaths, fem = d$femininity)) 
y.mean = apply(y.preds, 2, mean)
y.ci = apply(y.preds, 2, PI, prob = .89)
```

```{r}
preds = data.frame(actual_deaths = d$deaths,
                  actual_femininity = d$femininity,
                  predicted_deaths = y.mean,
                  lower_ci = y.ci[1,],
                  upper_ci = y.ci[2,])
head(preds, 3)
```


```{r}
ggplot(data = preds, aes(actual_femininity, actual_deaths, color = 'Actual Deaths'))+
  geom_point(size = .5)+
  geom_point(size = 1, aes(x = actual_femininity, y = y.mean, color = 'Model Predicted Deaths'))+
  geom_line(linetype = 'dotdash', aes(x = actual_femininity, y = upper_ci, color = 'CI Pred Deaths'))+
  geom_line(linetype = 'dotdash', aes(x = actual_femininity, y = lower_ci, color = 'CI Pred Deaths'))
```

The 89% interval of the expected value is surprisingly narrow. In this plot we can see that femininity accounts for very little of the variation in deaths, especially at the high end. Due to the over-dispersion in deaths this homogenous Poisson model does a poor job for most of the hurricanes in the sample, since most of them lie outside the dashed prediction boundaries.

# 2. Counts are nearly always over-dispersed relative to Poisson. So fit a gamma-Poisson (aka negative-binomial) model to predict deaths using femininity. 

https://discourse.mc-stan.org/t/error-in-stanc-c-exception-unknown-reason/2120

```{r}
d$fem_st = ( d$femininity - mean(d$femininity) )/sd(d$femininity)
dat_list = list(deaths = d$deaths,
                fem = d$fem_st)
```


```{r}
#fem_mod_nb <- ulam(alist(
 # deaths ~ dgampois( lambda, phi ),
  #log(lambda) <- a + b*fem,
#a ~ dnorm(0, .001),
#b ~ dnorm(0, .001),
#phi ~ dexp(1)
#), data=dat_list, chains=4 , cores = 4, log_lik=TRUE )
```

### Show that the over-dispersed model no longer shows as precise a positive association between femininity and deaths, with an 89% interval that overlaps zero. 

```{r}
# precis(fem_mod_nb)
```

```{r}
# compare(fem_mod_nb, fem_mod)
```

### Can you explain why the association diminished in strength?

# 3. Fit a series of models evaluating hurricane interactions.

In order to infer a strong association between deaths and femininity, it’s necessary to include an interaction effect. In the data, there are two measures of a hurricane’s potential to cause death: damage_norm and min_pressure. Consult ?Hurricanes for their meanings. It makes some sense to imagine that femininity of a name matters more when the hurricane is itself deadly. This implies an interaction between femininity and either or both of damage_norm and min_pressure.

```{r}
data(Hurricanes)
d <- Hurricanes
head(d)
```


```{r}
d$fmnnty_std <- ( d$femininity - mean(d$femininity) )/sd(d$femininity)
dat_list = list(deaths = d$deaths,
                fem = d$fmnnty_std,
                dam = d$damage_norm)


```


```{r}
start_list <- list(
a=.5,
b=.2,
c=.1
)

dam <- ulam(
alist(
deaths ~ dpois( lambda ),
log(lambda) <- a + b*fem + c*fem*dam,
a ~ dnorm(0,3),
b ~ dnorm(0,3),
c ~ dnorm(0,3)
), data=dat_list , iter = 3000, chains=4 , log_lik=TRUE, start = start_list )
```


```{r}
press <- ulam(
alist(
deaths ~ dpois( lambda ),
log(lambda) <- a + b*fem + c*fem*dam,
a ~ dnorm(0,3),
b ~ dnorm(0,3),
c ~ dnorm(0,3)
), data=dat_list , iter = 3000, chains=4 , log_lik=TRUE )
```

### Interpret and compare the models. 

In interpreting the estimates, it may help to generate counterfactual predictions contrasting hurricanes with masculine and feminine names. Are the effect sizes plausible?

# 4. Use the logarithm of damage_norm as a predictor

In the original hurricanes paper, storm damage (damage_norm) was used directly. This assumption implies that mortality increases exponentially with a linear increase in storm strength, because a Poisson regression uses a log link. So it’s worth exploring an alternative hypothesis: that the logarithm of storm strength is what matters. Use the best model structure from the previous problem, compare a model that uses log(damage_norm) to a model that uses damage_norm directly. 

Compare their DIC/WAIC values as well as their implied predictions. What do you conclude?

# 5. Evaluate this hypothesis, using the Trolley data, supposing that contact provides a proxy for physical harm.

One hypothesis from developmental psychology, usually attributed to Carol Gilligan, proposes that women and men have different average tendencies in moral reasoning. Like most hypotheses in social psychology, it is merely descriptive. The notion is that women are more concerned with care (avoiding harm), while men are more concerned with justice and rights. Culture-bound
nonsense? Yes. Descriptively accurate? Maybe.  Are women more or less bothered by contact than are men, in these data? Figure out the model(s) that is needed to address this question.

# 6. Model these data using zero-inflated Poisson GLMs. Predict fish_caught as a function of any of the other variables you think are relevant.

One thing you must do, however, is use a proper Poisson offset/exposure in the Poisson portion of the zero-inflated model. Then use the hours variable to construct the offset. This will adjust the model for the differing amount of time individuals spent in the park.

The data in data(Fish) are records of visits to a national park. See ?Fish for details. The question of interest is how many fish an average visitor takes per hour, when fishing. The problem is that not everyone tried to fish, so the fish_caught numbers are zero-inflated. As with the monks example in the chapter, there is a process that determines who is fishing (working) and another process that determines fish per hour (manuscripts per day), conditional on fishing (working). We want to model both. Otherwise we’ll end up with an underestimate of rate of fish extraction from the park.
 


